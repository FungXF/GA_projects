{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bdf66b-5833-4fa0-b2ba-b2929d72b8d6",
   "metadata": {},
   "source": [
    "# Reddit Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f9655-4413-40a6-a16d-dcb921257d0b",
   "metadata": {},
   "source": [
    "## Notebook 4 of 5 - (Vectorisation + Modelling) Part 2 of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602472d-1b16-4b0c-bd32-fc6a3ea37006",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22eaac92-2815-4d95-8f92-defb422bb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23cc523b-df9d-4eb1-974b-3e390bc7753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety_depression = pd.read_csv('datasets/anxiety_depression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0346ee34-d5c5-4e2d-a4e1-b95b655d6551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29907 entries, 0 to 29906\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   is_anxiety         29907 non-null  int64 \n",
      " 1   title_text         29907 non-null  object\n",
      " 2   date_time          29907 non-null  object\n",
      " 3   title_text_re      29907 non-null  object\n",
      " 4   status_length      29907 non-null  int64 \n",
      " 5   status_word_count  29907 non-null  int64 \n",
      " 6   day                29907 non-null  int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "anxiety_depression.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26460f80-8215-4416-8236-11ad2f44f1eb",
   "metadata": {},
   "source": [
    "# Pipeline Vectorisation + Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1ceaa-cf02-4f79-b7bd-65761a352a46",
   "metadata": {},
   "source": [
    "Pipeline 3 = TfidfVectorizer() + RandomForest  \n",
    "Pipeline 4 = TfidfVectorizer() + Pycaret Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdda65bc-54ab-4f96-b8c2-4b8aa2050a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that a new column was created after doing Regex, thus new 'X'\n",
    "X2 = anxiety_depression['title_text_re']\n",
    "y = anxiety_depression['is_anxiety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99da74ca-a3ac-4cfc-9f57-19dd592b46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2,y,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "138ca280-041c-4662-b7bd-2f0594e22a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.505283\n",
       "0    0.494717\n",
       "Name: is_anxiety, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset is balanced \n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f7ba77d-383b-40e9-828c-d7c815ab9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "class StemmTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = PorterStemmer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.stem(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83e1b033-8c4f-468d-8011-48e1fb502a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the custom stopwords from notebook 2\n",
    "stop_words = frozenset(['removed','deleted','anxiety','anxious','depression','depressed'])\n",
    "custom_stop_words = stop_words.union(TfidfVectorizer(stop_words = 'english').get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941bf86-6e1d-4271-99d4-db80d24ee41d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline 3: Random Forest Model\n",
    "- Using the best parameters evaluated from pipeline 2 for the vectorizer to use in RandomForest Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a764208a-8230-4aa3-9970-c6d12b2177b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Vectorizers\n",
    "tfidf = TfidfVectorizer(max_df = 0.9, \n",
    "                        max_features = 3000, \n",
    "                        min_df = 2, \n",
    "                        ngram_range= (1,1), \n",
    "                        stop_words = custom_stop_words, \n",
    "                        tokenizer = StemmTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd9c19f6-eb6e-4cb7-abaa-f86173bd817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on our corpus and transform it.\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f21b7730-d94b-48dc-ad3d-9bd10f5e88fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22430x3000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1050277 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After vectorization\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25222617-adfe-42e0-bac8-c8c644aaec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the X_test\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43816262-a02a-4f5d-8cc3-7ebf28ef9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4541a160-56b4-4436-bfc1-ecc9e78ad734",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START max_depth=3, n_estimators=100...............................\n",
      "[CV 1/5; 1/9] END max_depth=3, n_estimators=100;, score=0.866 total time=   0.5s\n",
      "[CV 2/5; 1/9] START max_depth=3, n_estimators=100...............................\n",
      "[CV 2/5; 1/9] END max_depth=3, n_estimators=100;, score=0.855 total time=   0.5s\n",
      "[CV 3/5; 1/9] START max_depth=3, n_estimators=100...............................\n",
      "[CV 3/5; 1/9] END max_depth=3, n_estimators=100;, score=0.863 total time=   0.5s\n",
      "[CV 4/5; 1/9] START max_depth=3, n_estimators=100...............................\n",
      "[CV 4/5; 1/9] END max_depth=3, n_estimators=100;, score=0.872 total time=   0.5s\n",
      "[CV 5/5; 1/9] START max_depth=3, n_estimators=100...............................\n",
      "[CV 5/5; 1/9] END max_depth=3, n_estimators=100;, score=0.867 total time=   0.5s\n",
      "[CV 1/5; 2/9] START max_depth=3, n_estimators=150...............................\n",
      "[CV 1/5; 2/9] END max_depth=3, n_estimators=150;, score=0.869 total time=   0.7s\n",
      "[CV 2/5; 2/9] START max_depth=3, n_estimators=150...............................\n",
      "[CV 2/5; 2/9] END max_depth=3, n_estimators=150;, score=0.865 total time=   0.8s\n",
      "[CV 3/5; 2/9] START max_depth=3, n_estimators=150...............................\n",
      "[CV 3/5; 2/9] END max_depth=3, n_estimators=150;, score=0.864 total time=   0.8s\n",
      "[CV 4/5; 2/9] START max_depth=3, n_estimators=150...............................\n",
      "[CV 4/5; 2/9] END max_depth=3, n_estimators=150;, score=0.877 total time=   0.8s\n",
      "[CV 5/5; 2/9] START max_depth=3, n_estimators=150...............................\n",
      "[CV 5/5; 2/9] END max_depth=3, n_estimators=150;, score=0.866 total time=   0.8s\n",
      "[CV 1/5; 3/9] START max_depth=3, n_estimators=200...............................\n",
      "[CV 1/5; 3/9] END max_depth=3, n_estimators=200;, score=0.869 total time=   1.1s\n",
      "[CV 2/5; 3/9] START max_depth=3, n_estimators=200...............................\n",
      "[CV 2/5; 3/9] END max_depth=3, n_estimators=200;, score=0.865 total time=   1.1s\n",
      "[CV 3/5; 3/9] START max_depth=3, n_estimators=200...............................\n",
      "[CV 3/5; 3/9] END max_depth=3, n_estimators=200;, score=0.873 total time=   1.1s\n",
      "[CV 4/5; 3/9] START max_depth=3, n_estimators=200...............................\n",
      "[CV 4/5; 3/9] END max_depth=3, n_estimators=200;, score=0.870 total time=   1.1s\n",
      "[CV 5/5; 3/9] START max_depth=3, n_estimators=200...............................\n",
      "[CV 5/5; 3/9] END max_depth=3, n_estimators=200;, score=0.873 total time=   1.1s\n",
      "[CV 1/5; 4/9] START max_depth=4, n_estimators=100...............................\n",
      "[CV 1/5; 4/9] END max_depth=4, n_estimators=100;, score=0.857 total time=   0.6s\n",
      "[CV 2/5; 4/9] START max_depth=4, n_estimators=100...............................\n",
      "[CV 2/5; 4/9] END max_depth=4, n_estimators=100;, score=0.859 total time=   0.6s\n",
      "[CV 3/5; 4/9] START max_depth=4, n_estimators=100...............................\n",
      "[CV 3/5; 4/9] END max_depth=4, n_estimators=100;, score=0.858 total time=   0.6s\n",
      "[CV 4/5; 4/9] START max_depth=4, n_estimators=100...............................\n",
      "[CV 4/5; 4/9] END max_depth=4, n_estimators=100;, score=0.866 total time=   0.6s\n",
      "[CV 5/5; 4/9] START max_depth=4, n_estimators=100...............................\n",
      "[CV 5/5; 4/9] END max_depth=4, n_estimators=100;, score=0.868 total time=   0.6s\n",
      "[CV 1/5; 5/9] START max_depth=4, n_estimators=150...............................\n",
      "[CV 1/5; 5/9] END max_depth=4, n_estimators=150;, score=0.864 total time=   1.0s\n",
      "[CV 2/5; 5/9] START max_depth=4, n_estimators=150...............................\n",
      "[CV 2/5; 5/9] END max_depth=4, n_estimators=150;, score=0.857 total time=   1.0s\n",
      "[CV 3/5; 5/9] START max_depth=4, n_estimators=150...............................\n",
      "[CV 3/5; 5/9] END max_depth=4, n_estimators=150;, score=0.862 total time=   1.0s\n",
      "[CV 4/5; 5/9] START max_depth=4, n_estimators=150...............................\n",
      "[CV 4/5; 5/9] END max_depth=4, n_estimators=150;, score=0.877 total time=   1.0s\n",
      "[CV 5/5; 5/9] START max_depth=4, n_estimators=150...............................\n",
      "[CV 5/5; 5/9] END max_depth=4, n_estimators=150;, score=0.871 total time=   1.0s\n",
      "[CV 1/5; 6/9] START max_depth=4, n_estimators=200...............................\n",
      "[CV 1/5; 6/9] END max_depth=4, n_estimators=200;, score=0.868 total time=   1.3s\n",
      "[CV 2/5; 6/9] START max_depth=4, n_estimators=200...............................\n",
      "[CV 2/5; 6/9] END max_depth=4, n_estimators=200;, score=0.864 total time=   1.4s\n",
      "[CV 3/5; 6/9] START max_depth=4, n_estimators=200...............................\n",
      "[CV 3/5; 6/9] END max_depth=4, n_estimators=200;, score=0.867 total time=   1.3s\n",
      "[CV 4/5; 6/9] START max_depth=4, n_estimators=200...............................\n",
      "[CV 4/5; 6/9] END max_depth=4, n_estimators=200;, score=0.876 total time=   1.3s\n",
      "[CV 5/5; 6/9] START max_depth=4, n_estimators=200...............................\n",
      "[CV 5/5; 6/9] END max_depth=4, n_estimators=200;, score=0.868 total time=   1.3s\n",
      "[CV 1/5; 7/9] START max_depth=5, n_estimators=100...............................\n",
      "[CV 1/5; 7/9] END max_depth=5, n_estimators=100;, score=0.873 total time=   0.8s\n",
      "[CV 2/5; 7/9] START max_depth=5, n_estimators=100...............................\n",
      "[CV 2/5; 7/9] END max_depth=5, n_estimators=100;, score=0.870 total time=   0.8s\n",
      "[CV 3/5; 7/9] START max_depth=5, n_estimators=100...............................\n",
      "[CV 3/5; 7/9] END max_depth=5, n_estimators=100;, score=0.863 total time=   0.8s\n",
      "[CV 4/5; 7/9] START max_depth=5, n_estimators=100...............................\n",
      "[CV 4/5; 7/9] END max_depth=5, n_estimators=100;, score=0.882 total time=   0.8s\n",
      "[CV 5/5; 7/9] START max_depth=5, n_estimators=100...............................\n",
      "[CV 5/5; 7/9] END max_depth=5, n_estimators=100;, score=0.870 total time=   0.8s\n",
      "[CV 1/5; 8/9] START max_depth=5, n_estimators=150...............................\n",
      "[CV 1/5; 8/9] END max_depth=5, n_estimators=150;, score=0.874 total time=   1.2s\n",
      "[CV 2/5; 8/9] START max_depth=5, n_estimators=150...............................\n",
      "[CV 2/5; 8/9] END max_depth=5, n_estimators=150;, score=0.866 total time=   1.2s\n",
      "[CV 3/5; 8/9] START max_depth=5, n_estimators=150...............................\n",
      "[CV 3/5; 8/9] END max_depth=5, n_estimators=150;, score=0.869 total time=   1.2s\n",
      "[CV 4/5; 8/9] START max_depth=5, n_estimators=150...............................\n",
      "[CV 4/5; 8/9] END max_depth=5, n_estimators=150;, score=0.871 total time=   1.2s\n",
      "[CV 5/5; 8/9] START max_depth=5, n_estimators=150...............................\n",
      "[CV 5/5; 8/9] END max_depth=5, n_estimators=150;, score=0.864 total time=   1.2s\n",
      "[CV 1/5; 9/9] START max_depth=5, n_estimators=200...............................\n",
      "[CV 1/5; 9/9] END max_depth=5, n_estimators=200;, score=0.873 total time=   1.6s\n",
      "[CV 2/5; 9/9] START max_depth=5, n_estimators=200...............................\n",
      "[CV 2/5; 9/9] END max_depth=5, n_estimators=200;, score=0.874 total time=   1.6s\n",
      "[CV 3/5; 9/9] START max_depth=5, n_estimators=200...............................\n",
      "[CV 3/5; 9/9] END max_depth=5, n_estimators=200;, score=0.874 total time=   1.5s\n",
      "[CV 4/5; 9/9] START max_depth=5, n_estimators=200...............................\n",
      "[CV 4/5; 9/9] END max_depth=5, n_estimators=200;, score=0.880 total time=   1.6s\n",
      "[CV 5/5; 9/9] START max_depth=5, n_estimators=200...............................\n",
      "[CV 5/5; 9/9] END max_depth=5, n_estimators=200;, score=0.878 total time=   1.6s\n",
      "Stored 'gs3_fit' (GridSearchCV)\n",
      "Stored 'gs3' (GridSearchCV)\n",
      "0.8757467677218012\n",
      "CPU times: total: 50.6 s\n",
      "Wall time: 50.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 200}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200], # iterating over different number of trees in the forest\n",
    "    'max_depth': [3, 4, 5], # iterating over a defined set of max depth of tree. For None, the nodes are expanded until all leaves are pure\n",
    "}\n",
    "gs3 = GridSearchCV(rf, param_grid=rf_params, cv=5, verbose=10)\n",
    "gs3_fit = gs3.fit(X_train_tfidf, y_train)\n",
    "%store gs3_fit\n",
    "%store gs3\n",
    "\n",
    "print(gs3.best_score_)\n",
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b91e79b5-d78f-4389-a7dc-e0d5b1bfea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794917521176995"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score of train on pipeline 3\n",
    "gs3.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d73610cf-e5ee-495b-a28e-93e7ee6f3a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872274976594891"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score of test on pipeline 3\n",
    "gs3.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb354e1d-16c4-40be-9dc8-36475875c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from X_test\n",
    "predictions3 = gs3.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e582c4fa-9d9a-4f13-ac62-98a3ec4a9b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3412,  287],\n",
       "       [ 668, 3110]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the confusion matrix from the predicted labels and compared to true labels\n",
    "confusion_matrix(y_test, predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cec3ece-468d-418a-9cb7-405f2927ec49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions3)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['depression', 'anxiety'])\n",
    "disp.plot()\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ad0d6a-7b0e-41f8-a360-1257a0f59bcf",
   "metadata": {},
   "source": [
    "- The train score for pipeline 3 is at 87.9% and the test score at 87.2% which the train and test score is much closer than the base model but test score is lower than the base model. \n",
    "- Pipeline 3 has the lowest accuracy score than the rest of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf922b2-4b20-40e2-ab9f-83957712bb5b",
   "metadata": {},
   "source": [
    "## Pycaret Models\n",
    "- Using the best parameters evaluated from pipeline 2 for the vectorizer was used together with the pycaret model for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d166e25-76ef-47e5-866f-b57f7305ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Vectorizers\n",
    "tfidf2 = TfidfVectorizer(max_df = 0.9, \n",
    "                        max_features = 3000, \n",
    "                        min_df = 2, \n",
    "                        ngram_range= (1,1), \n",
    "                        stop_words = custom_stop_words, \n",
    "                        tokenizer = StemmTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c6815be-fbd6-42a5-95c8-4ca40bce460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train data through the vectorizer and set it as a dataframe\n",
    "X_train_tfidf_df = pd.DataFrame(tfidf2.fit_transform(X_train.values).todense(),columns = tfidf2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f65535d2-a467-487a-a47f-963446f33f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test data through the vectorizer and set it as a dataframe\n",
    "X_test_tfidf_df = pd.DataFrame(tfidf2.transform(X_test.values).todense(),columns = tfidf2.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2d7709e-4f8e-4905-b1b9-eb3d65d2287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the train data as a single dataframe to use it in pycaret model\n",
    "pycaret_df = pd.concat([X_train_tfidf_df, y_train.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bf615a8-237d-457d-8504-83df15a51a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22430, 3001)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycaret_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "054e589d-24de-4fbe-a1c2-bce643f5ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22430 entries, 0 to 22429\n",
      "Columns: 3001 entries, abandon to is_anxiety\n",
      "dtypes: float64(3000), int64(1)\n",
      "memory usage: 513.6 MB\n"
     ]
    }
   ],
   "source": [
    "pycaret_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f01eccf0-d222-4afe-a4b5-6ff54a1cad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since pycaret seperates features and target we will set the features to the vectorized columns.\n",
    "vectorized_cols = list(X_train_tfidf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b77bcd8f-65fd-41e6-aa0e-2d49055668b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "22425    0\n",
       "22426    1\n",
       "22427    1\n",
       "22428    1\n",
       "22429    1\n",
       "Name: is_anxiety, Length: 22430, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycaret_df['is_anxiety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6b58f79-ba23-458f-9392-7749b674ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22beef68-8d19-4cae-a7f4-c6c495e8e71e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ea197_row8_col1, #T_ea197_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ea197\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ea197_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_ea197_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ea197_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_ea197_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ea197_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_ea197_row1_col1\" class=\"data row1 col1\" >is_anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ea197_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_ea197_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ea197_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_ea197_row3_col1\" class=\"data row3 col1\" >(22430, 3001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ea197_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_ea197_row4_col1\" class=\"data row4 col1\" >(22430, 3001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ea197_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_ea197_row5_col1\" class=\"data row5 col1\" >(15700, 3001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ea197_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_ea197_row6_col1\" class=\"data row6 col1\" >(6730, 3001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ea197_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_ea197_row7_col1\" class=\"data row7 col1\" >3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ea197_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_ea197_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ea197_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_ea197_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ea197_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_ea197_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ea197_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_ea197_row11_col1\" class=\"data row11 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ea197_row12_col0\" class=\"data row12 col0\" >Low variance threshold</td>\n",
       "      <td id=\"T_ea197_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ea197_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_ea197_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ea197_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_ea197_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ea197_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_ea197_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ea197_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_ea197_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ea197_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_ea197_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ea197_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_ea197_row18_col1\" class=\"data row18 col1\" >anxiety_depression_project_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea197_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ea197_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_ea197_row19_col1\" class=\"data row19 col1\" >5843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x138ee40d1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_experiment = setup(data = pycaret_df,\n",
    "                       numeric_features = vectorized_cols,\n",
    "                       target = 'is_anxiety',\n",
    "                       use_gpu = True,\n",
    "                       session_id=42, \n",
    "                       experiment_name='anxiety_depression_project_3'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c99cb3cb-012b-404b-a921-8ceca5bc0f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25b0d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_25b0d_row0_col0, #T_25b0d_row0_col3, #T_25b0d_row0_col4, #T_25b0d_row0_col5, #T_25b0d_row1_col0, #T_25b0d_row1_col1, #T_25b0d_row1_col2, #T_25b0d_row1_col3, #T_25b0d_row1_col4, #T_25b0d_row1_col6, #T_25b0d_row1_col7, #T_25b0d_row2_col0, #T_25b0d_row2_col1, #T_25b0d_row2_col2, #T_25b0d_row2_col3, #T_25b0d_row2_col5, #T_25b0d_row2_col6, #T_25b0d_row2_col7, #T_25b0d_row3_col0, #T_25b0d_row3_col1, #T_25b0d_row3_col2, #T_25b0d_row3_col3, #T_25b0d_row3_col4, #T_25b0d_row3_col5, #T_25b0d_row3_col6, #T_25b0d_row3_col7, #T_25b0d_row4_col0, #T_25b0d_row4_col1, #T_25b0d_row4_col2, #T_25b0d_row4_col3, #T_25b0d_row4_col4, #T_25b0d_row4_col5, #T_25b0d_row4_col6, #T_25b0d_row4_col7, #T_25b0d_row5_col0, #T_25b0d_row5_col1, #T_25b0d_row5_col2, #T_25b0d_row5_col3, #T_25b0d_row5_col4, #T_25b0d_row5_col5, #T_25b0d_row5_col6, #T_25b0d_row5_col7, #T_25b0d_row6_col0, #T_25b0d_row6_col1, #T_25b0d_row6_col2, #T_25b0d_row6_col3, #T_25b0d_row6_col4, #T_25b0d_row6_col5, #T_25b0d_row6_col6, #T_25b0d_row6_col7, #T_25b0d_row7_col0, #T_25b0d_row7_col1, #T_25b0d_row7_col2, #T_25b0d_row7_col3, #T_25b0d_row7_col4, #T_25b0d_row7_col5, #T_25b0d_row7_col6, #T_25b0d_row7_col7, #T_25b0d_row8_col0, #T_25b0d_row8_col1, #T_25b0d_row8_col2, #T_25b0d_row8_col3, #T_25b0d_row8_col4, #T_25b0d_row8_col5, #T_25b0d_row8_col6, #T_25b0d_row8_col7, #T_25b0d_row9_col0, #T_25b0d_row9_col1, #T_25b0d_row9_col2, #T_25b0d_row9_col3, #T_25b0d_row9_col4, #T_25b0d_row9_col5, #T_25b0d_row9_col6, #T_25b0d_row9_col7, #T_25b0d_row10_col0, #T_25b0d_row10_col1, #T_25b0d_row10_col2, #T_25b0d_row10_col3, #T_25b0d_row10_col4, #T_25b0d_row10_col5, #T_25b0d_row10_col6, #T_25b0d_row10_col7, #T_25b0d_row11_col0, #T_25b0d_row11_col1, #T_25b0d_row11_col2, #T_25b0d_row11_col3, #T_25b0d_row11_col4, #T_25b0d_row11_col5, #T_25b0d_row11_col6, #T_25b0d_row11_col7, #T_25b0d_row12_col0, #T_25b0d_row12_col1, #T_25b0d_row12_col2, #T_25b0d_row12_col3, #T_25b0d_row12_col4, #T_25b0d_row12_col5, #T_25b0d_row12_col6, #T_25b0d_row12_col7, #T_25b0d_row13_col0, #T_25b0d_row13_col1, #T_25b0d_row13_col2, #T_25b0d_row13_col4, #T_25b0d_row13_col5, #T_25b0d_row13_col6, #T_25b0d_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_25b0d_row0_col1, #T_25b0d_row0_col2, #T_25b0d_row0_col6, #T_25b0d_row0_col7, #T_25b0d_row1_col5, #T_25b0d_row2_col4, #T_25b0d_row13_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_25b0d_row0_col8, #T_25b0d_row1_col8, #T_25b0d_row2_col8, #T_25b0d_row3_col8, #T_25b0d_row4_col8, #T_25b0d_row5_col8, #T_25b0d_row6_col8, #T_25b0d_row7_col8, #T_25b0d_row8_col8, #T_25b0d_row9_col8, #T_25b0d_row10_col8, #T_25b0d_row11_col8, #T_25b0d_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_25b0d_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25b0d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_25b0d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_25b0d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_25b0d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_25b0d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_25b0d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_25b0d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_25b0d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_25b0d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_25b0d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_25b0d_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_25b0d_row0_col1\" class=\"data row0 col1\" >0.9017</td>\n",
       "      <td id=\"T_25b0d_row0_col2\" class=\"data row0 col2\" >0.9609</td>\n",
       "      <td id=\"T_25b0d_row0_col3\" class=\"data row0 col3\" >0.8843</td>\n",
       "      <td id=\"T_25b0d_row0_col4\" class=\"data row0 col4\" >0.9182</td>\n",
       "      <td id=\"T_25b0d_row0_col5\" class=\"data row0 col5\" >0.9009</td>\n",
       "      <td id=\"T_25b0d_row0_col6\" class=\"data row0 col6\" >0.8035</td>\n",
       "      <td id=\"T_25b0d_row0_col7\" class=\"data row0 col7\" >0.8041</td>\n",
       "      <td id=\"T_25b0d_row0_col8\" class=\"data row0 col8\" >7.6120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_25b0d_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_25b0d_row1_col1\" class=\"data row1 col1\" >0.9016</td>\n",
       "      <td id=\"T_25b0d_row1_col2\" class=\"data row1 col2\" >0.9598</td>\n",
       "      <td id=\"T_25b0d_row1_col3\" class=\"data row1 col3\" >0.8874</td>\n",
       "      <td id=\"T_25b0d_row1_col4\" class=\"data row1 col4\" >0.9152</td>\n",
       "      <td id=\"T_25b0d_row1_col5\" class=\"data row1 col5\" >0.9011</td>\n",
       "      <td id=\"T_25b0d_row1_col6\" class=\"data row1 col6\" >0.8032</td>\n",
       "      <td id=\"T_25b0d_row1_col7\" class=\"data row1 col7\" >0.8036</td>\n",
       "      <td id=\"T_25b0d_row1_col8\" class=\"data row1 col8\" >7.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row2\" class=\"row_heading level0 row2\" >svm</th>\n",
       "      <td id=\"T_25b0d_row2_col0\" class=\"data row2 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_25b0d_row2_col1\" class=\"data row2 col1\" >0.8976</td>\n",
       "      <td id=\"T_25b0d_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_25b0d_row2_col3\" class=\"data row2 col3\" >0.8733</td>\n",
       "      <td id=\"T_25b0d_row2_col4\" class=\"data row2 col4\" >0.9203</td>\n",
       "      <td id=\"T_25b0d_row2_col5\" class=\"data row2 col5\" >0.8959</td>\n",
       "      <td id=\"T_25b0d_row2_col6\" class=\"data row2 col6\" >0.7952</td>\n",
       "      <td id=\"T_25b0d_row2_col7\" class=\"data row2 col7\" >0.7967</td>\n",
       "      <td id=\"T_25b0d_row2_col8\" class=\"data row2 col8\" >2.9780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_25b0d_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_25b0d_row3_col1\" class=\"data row3 col1\" >0.8937</td>\n",
       "      <td id=\"T_25b0d_row3_col2\" class=\"data row3 col2\" >0.9515</td>\n",
       "      <td id=\"T_25b0d_row3_col3\" class=\"data row3 col3\" >0.8810</td>\n",
       "      <td id=\"T_25b0d_row3_col4\" class=\"data row3 col4\" >0.9060</td>\n",
       "      <td id=\"T_25b0d_row3_col5\" class=\"data row3 col5\" >0.8933</td>\n",
       "      <td id=\"T_25b0d_row3_col6\" class=\"data row3 col6\" >0.7874</td>\n",
       "      <td id=\"T_25b0d_row3_col7\" class=\"data row3 col7\" >0.7878</td>\n",
       "      <td id=\"T_25b0d_row3_col8\" class=\"data row3 col8\" >7.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n",
       "      <td id=\"T_25b0d_row4_col0\" class=\"data row4 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_25b0d_row4_col1\" class=\"data row4 col1\" >0.8915</td>\n",
       "      <td id=\"T_25b0d_row4_col2\" class=\"data row4 col2\" >0.9472</td>\n",
       "      <td id=\"T_25b0d_row4_col3\" class=\"data row4 col3\" >0.8859</td>\n",
       "      <td id=\"T_25b0d_row4_col4\" class=\"data row4 col4\" >0.8980</td>\n",
       "      <td id=\"T_25b0d_row4_col5\" class=\"data row4 col5\" >0.8919</td>\n",
       "      <td id=\"T_25b0d_row4_col6\" class=\"data row4 col6\" >0.7829</td>\n",
       "      <td id=\"T_25b0d_row4_col7\" class=\"data row4 col7\" >0.7831</td>\n",
       "      <td id=\"T_25b0d_row4_col8\" class=\"data row4 col8\" >10.9260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "      <td id=\"T_25b0d_row5_col0\" class=\"data row5 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_25b0d_row5_col1\" class=\"data row5 col1\" >0.8882</td>\n",
       "      <td id=\"T_25b0d_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_25b0d_row5_col3\" class=\"data row5 col3\" >0.8631</td>\n",
       "      <td id=\"T_25b0d_row5_col4\" class=\"data row5 col4\" >0.9109</td>\n",
       "      <td id=\"T_25b0d_row5_col5\" class=\"data row5 col5\" >0.8863</td>\n",
       "      <td id=\"T_25b0d_row5_col6\" class=\"data row5 col6\" >0.7764</td>\n",
       "      <td id=\"T_25b0d_row5_col7\" class=\"data row5 col7\" >0.7776</td>\n",
       "      <td id=\"T_25b0d_row5_col8\" class=\"data row5 col8\" >2.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row6\" class=\"row_heading level0 row6\" >gbc</th>\n",
       "      <td id=\"T_25b0d_row6_col0\" class=\"data row6 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_25b0d_row6_col1\" class=\"data row6 col1\" >0.8871</td>\n",
       "      <td id=\"T_25b0d_row6_col2\" class=\"data row6 col2\" >0.9514</td>\n",
       "      <td id=\"T_25b0d_row6_col3\" class=\"data row6 col3\" >0.8599</td>\n",
       "      <td id=\"T_25b0d_row6_col4\" class=\"data row6 col4\" >0.9116</td>\n",
       "      <td id=\"T_25b0d_row6_col5\" class=\"data row6 col5\" >0.8850</td>\n",
       "      <td id=\"T_25b0d_row6_col6\" class=\"data row6 col6\" >0.7744</td>\n",
       "      <td id=\"T_25b0d_row6_col7\" class=\"data row6 col7\" >0.7757</td>\n",
       "      <td id=\"T_25b0d_row6_col8\" class=\"data row6 col8\" >55.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row7\" class=\"row_heading level0 row7\" >ada</th>\n",
       "      <td id=\"T_25b0d_row7_col0\" class=\"data row7 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_25b0d_row7_col1\" class=\"data row7 col1\" >0.8754</td>\n",
       "      <td id=\"T_25b0d_row7_col2\" class=\"data row7 col2\" >0.9432</td>\n",
       "      <td id=\"T_25b0d_row7_col3\" class=\"data row7 col3\" >0.8734</td>\n",
       "      <td id=\"T_25b0d_row7_col4\" class=\"data row7 col4\" >0.8792</td>\n",
       "      <td id=\"T_25b0d_row7_col5\" class=\"data row7 col5\" >0.8763</td>\n",
       "      <td id=\"T_25b0d_row7_col6\" class=\"data row7 col6\" >0.7508</td>\n",
       "      <td id=\"T_25b0d_row7_col7\" class=\"data row7 col7\" >0.7509</td>\n",
       "      <td id=\"T_25b0d_row7_col8\" class=\"data row7 col8\" >14.3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_25b0d_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_25b0d_row8_col1\" class=\"data row8 col1\" >0.8632</td>\n",
       "      <td id=\"T_25b0d_row8_col2\" class=\"data row8 col2\" >0.9341</td>\n",
       "      <td id=\"T_25b0d_row8_col3\" class=\"data row8 col3\" >0.8438</td>\n",
       "      <td id=\"T_25b0d_row8_col4\" class=\"data row8 col4\" >0.8805</td>\n",
       "      <td id=\"T_25b0d_row8_col5\" class=\"data row8 col5\" >0.8617</td>\n",
       "      <td id=\"T_25b0d_row8_col6\" class=\"data row8 col6\" >0.7266</td>\n",
       "      <td id=\"T_25b0d_row8_col7\" class=\"data row8 col7\" >0.7273</td>\n",
       "      <td id=\"T_25b0d_row8_col8\" class=\"data row8 col8\" >16.7560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row9\" class=\"row_heading level0 row9\" >dt</th>\n",
       "      <td id=\"T_25b0d_row9_col0\" class=\"data row9 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_25b0d_row9_col1\" class=\"data row9 col1\" >0.8276</td>\n",
       "      <td id=\"T_25b0d_row9_col2\" class=\"data row9 col2\" >0.8286</td>\n",
       "      <td id=\"T_25b0d_row9_col3\" class=\"data row9 col3\" >0.8244</td>\n",
       "      <td id=\"T_25b0d_row9_col4\" class=\"data row9 col4\" >0.8329</td>\n",
       "      <td id=\"T_25b0d_row9_col5\" class=\"data row9 col5\" >0.8286</td>\n",
       "      <td id=\"T_25b0d_row9_col6\" class=\"data row9 col6\" >0.6553</td>\n",
       "      <td id=\"T_25b0d_row9_col7\" class=\"data row9 col7\" >0.6554</td>\n",
       "      <td id=\"T_25b0d_row9_col8\" class=\"data row9 col8\" >12.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_25b0d_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_25b0d_row10_col1\" class=\"data row10 col1\" >0.7513</td>\n",
       "      <td id=\"T_25b0d_row10_col2\" class=\"data row10 col2\" >0.8014</td>\n",
       "      <td id=\"T_25b0d_row10_col3\" class=\"data row10 col3\" >0.6630</td>\n",
       "      <td id=\"T_25b0d_row10_col4\" class=\"data row10 col4\" >0.8105</td>\n",
       "      <td id=\"T_25b0d_row10_col5\" class=\"data row10 col5\" >0.7292</td>\n",
       "      <td id=\"T_25b0d_row10_col6\" class=\"data row10 col6\" >0.5036</td>\n",
       "      <td id=\"T_25b0d_row10_col7\" class=\"data row10 col7\" >0.5124</td>\n",
       "      <td id=\"T_25b0d_row10_col8\" class=\"data row10 col8\" >2.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row11\" class=\"row_heading level0 row11\" >knn</th>\n",
       "      <td id=\"T_25b0d_row11_col0\" class=\"data row11 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_25b0d_row11_col1\" class=\"data row11 col1\" >0.7496</td>\n",
       "      <td id=\"T_25b0d_row11_col2\" class=\"data row11 col2\" >0.8201</td>\n",
       "      <td id=\"T_25b0d_row11_col3\" class=\"data row11 col3\" >0.8316</td>\n",
       "      <td id=\"T_25b0d_row11_col4\" class=\"data row11 col4\" >0.7223</td>\n",
       "      <td id=\"T_25b0d_row11_col5\" class=\"data row11 col5\" >0.7702</td>\n",
       "      <td id=\"T_25b0d_row11_col6\" class=\"data row11 col6\" >0.4983</td>\n",
       "      <td id=\"T_25b0d_row11_col7\" class=\"data row11 col7\" >0.5094</td>\n",
       "      <td id=\"T_25b0d_row11_col8\" class=\"data row11 col8\" >5.3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_25b0d_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_25b0d_row12_col1\" class=\"data row12 col1\" >0.5544</td>\n",
       "      <td id=\"T_25b0d_row12_col2\" class=\"data row12 col2\" >0.5549</td>\n",
       "      <td id=\"T_25b0d_row12_col3\" class=\"data row12 col3\" >0.9455</td>\n",
       "      <td id=\"T_25b0d_row12_col4\" class=\"data row12 col4\" >0.5567</td>\n",
       "      <td id=\"T_25b0d_row12_col5\" class=\"data row12 col5\" >0.6861</td>\n",
       "      <td id=\"T_25b0d_row12_col6\" class=\"data row12 col6\" >0.1005</td>\n",
       "      <td id=\"T_25b0d_row12_col7\" class=\"data row12 col7\" >0.1218</td>\n",
       "      <td id=\"T_25b0d_row12_col8\" class=\"data row12 col8\" >21.1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25b0d_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_25b0d_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_25b0d_row13_col1\" class=\"data row13 col1\" >0.5052</td>\n",
       "      <td id=\"T_25b0d_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_25b0d_row13_col3\" class=\"data row13 col3\" >1.0000</td>\n",
       "      <td id=\"T_25b0d_row13_col4\" class=\"data row13 col4\" >0.5052</td>\n",
       "      <td id=\"T_25b0d_row13_col5\" class=\"data row13 col5\" >0.6713</td>\n",
       "      <td id=\"T_25b0d_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_25b0d_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_25b0d_row13_col8\" class=\"data row13 col8\" >1.3530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13970241220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models(n_select = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c46e59d-417a-4ef9-b401-265d9323065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'best_model' (list)\n"
     ]
    }
   ],
   "source": [
    "best_model = best_model\n",
    "%store best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b046ed75-b2b6-4513-a3b9-72590cb81a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters for Logistic Regression\n",
    "best_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6796c2d3-1172-4842-9e80-cee35d25bfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8d269_row10_col0, #T_8d269_row10_col1, #T_8d269_row10_col2, #T_8d269_row10_col3, #T_8d269_row10_col4, #T_8d269_row10_col5, #T_8d269_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8d269\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8d269_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_8d269_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_8d269_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_8d269_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_8d269_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_8d269_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_8d269_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8d269_row0_col0\" class=\"data row0 col0\" >0.9019</td>\n",
       "      <td id=\"T_8d269_row0_col1\" class=\"data row0 col1\" >0.9600</td>\n",
       "      <td id=\"T_8d269_row0_col2\" class=\"data row0 col2\" >0.8852</td>\n",
       "      <td id=\"T_8d269_row0_col3\" class=\"data row0 col3\" >0.9176</td>\n",
       "      <td id=\"T_8d269_row0_col4\" class=\"data row0 col4\" >0.9012</td>\n",
       "      <td id=\"T_8d269_row0_col5\" class=\"data row0 col5\" >0.8039</td>\n",
       "      <td id=\"T_8d269_row0_col6\" class=\"data row0 col6\" >0.8044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8d269_row1_col0\" class=\"data row1 col0\" >0.9006</td>\n",
       "      <td id=\"T_8d269_row1_col1\" class=\"data row1 col1\" >0.9574</td>\n",
       "      <td id=\"T_8d269_row1_col2\" class=\"data row1 col2\" >0.8714</td>\n",
       "      <td id=\"T_8d269_row1_col3\" class=\"data row1 col3\" >0.9275</td>\n",
       "      <td id=\"T_8d269_row1_col4\" class=\"data row1 col4\" >0.8986</td>\n",
       "      <td id=\"T_8d269_row1_col5\" class=\"data row1 col5\" >0.8014</td>\n",
       "      <td id=\"T_8d269_row1_col6\" class=\"data row1 col6\" >0.8029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8d269_row2_col0\" class=\"data row2 col0\" >0.9000</td>\n",
       "      <td id=\"T_8d269_row2_col1\" class=\"data row2 col1\" >0.9588</td>\n",
       "      <td id=\"T_8d269_row2_col2\" class=\"data row2 col2\" >0.8840</td>\n",
       "      <td id=\"T_8d269_row2_col3\" class=\"data row2 col3\" >0.9151</td>\n",
       "      <td id=\"T_8d269_row2_col4\" class=\"data row2 col4\" >0.8993</td>\n",
       "      <td id=\"T_8d269_row2_col5\" class=\"data row2 col5\" >0.8000</td>\n",
       "      <td id=\"T_8d269_row2_col6\" class=\"data row2 col6\" >0.8005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8d269_row3_col0\" class=\"data row3 col0\" >0.9185</td>\n",
       "      <td id=\"T_8d269_row3_col1\" class=\"data row3 col1\" >0.9705</td>\n",
       "      <td id=\"T_8d269_row3_col2\" class=\"data row3 col2\" >0.9054</td>\n",
       "      <td id=\"T_8d269_row3_col3\" class=\"data row3 col3\" >0.9313</td>\n",
       "      <td id=\"T_8d269_row3_col4\" class=\"data row3 col4\" >0.9182</td>\n",
       "      <td id=\"T_8d269_row3_col5\" class=\"data row3 col5\" >0.8370</td>\n",
       "      <td id=\"T_8d269_row3_col6\" class=\"data row3 col6\" >0.8373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8d269_row4_col0\" class=\"data row4 col0\" >0.8987</td>\n",
       "      <td id=\"T_8d269_row4_col1\" class=\"data row4 col1\" >0.9620</td>\n",
       "      <td id=\"T_8d269_row4_col2\" class=\"data row4 col2\" >0.8827</td>\n",
       "      <td id=\"T_8d269_row4_col3\" class=\"data row4 col3\" >0.9138</td>\n",
       "      <td id=\"T_8d269_row4_col4\" class=\"data row4 col4\" >0.8980</td>\n",
       "      <td id=\"T_8d269_row4_col5\" class=\"data row4 col5\" >0.7975</td>\n",
       "      <td id=\"T_8d269_row4_col6\" class=\"data row4 col6\" >0.7980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8d269_row5_col0\" class=\"data row5 col0\" >0.8936</td>\n",
       "      <td id=\"T_8d269_row5_col1\" class=\"data row5 col1\" >0.9582</td>\n",
       "      <td id=\"T_8d269_row5_col2\" class=\"data row5 col2\" >0.8852</td>\n",
       "      <td id=\"T_8d269_row5_col3\" class=\"data row5 col3\" >0.9023</td>\n",
       "      <td id=\"T_8d269_row5_col4\" class=\"data row5 col4\" >0.8937</td>\n",
       "      <td id=\"T_8d269_row5_col5\" class=\"data row5 col5\" >0.7873</td>\n",
       "      <td id=\"T_8d269_row5_col6\" class=\"data row5 col6\" >0.7874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_8d269_row6_col0\" class=\"data row6 col0\" >0.9102</td>\n",
       "      <td id=\"T_8d269_row6_col1\" class=\"data row6 col1\" >0.9652</td>\n",
       "      <td id=\"T_8d269_row6_col2\" class=\"data row6 col2\" >0.8966</td>\n",
       "      <td id=\"T_8d269_row6_col3\" class=\"data row6 col3\" >0.9234</td>\n",
       "      <td id=\"T_8d269_row6_col4\" class=\"data row6 col4\" >0.9098</td>\n",
       "      <td id=\"T_8d269_row6_col5\" class=\"data row6 col5\" >0.8204</td>\n",
       "      <td id=\"T_8d269_row6_col6\" class=\"data row6 col6\" >0.8208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_8d269_row7_col0\" class=\"data row7 col0\" >0.8975</td>\n",
       "      <td id=\"T_8d269_row7_col1\" class=\"data row7 col1\" >0.9601</td>\n",
       "      <td id=\"T_8d269_row7_col2\" class=\"data row7 col2\" >0.8827</td>\n",
       "      <td id=\"T_8d269_row7_col3\" class=\"data row7 col3\" >0.9115</td>\n",
       "      <td id=\"T_8d269_row7_col4\" class=\"data row7 col4\" >0.8969</td>\n",
       "      <td id=\"T_8d269_row7_col5\" class=\"data row7 col5\" >0.7949</td>\n",
       "      <td id=\"T_8d269_row7_col6\" class=\"data row7 col6\" >0.7954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_8d269_row8_col0\" class=\"data row8 col0\" >0.8968</td>\n",
       "      <td id=\"T_8d269_row8_col1\" class=\"data row8 col1\" >0.9582</td>\n",
       "      <td id=\"T_8d269_row8_col2\" class=\"data row8 col2\" >0.8690</td>\n",
       "      <td id=\"T_8d269_row8_col3\" class=\"data row8 col3\" >0.9225</td>\n",
       "      <td id=\"T_8d269_row8_col4\" class=\"data row8 col4\" >0.8949</td>\n",
       "      <td id=\"T_8d269_row8_col5\" class=\"data row8 col5\" >0.7937</td>\n",
       "      <td id=\"T_8d269_row8_col6\" class=\"data row8 col6\" >0.7951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_8d269_row9_col0\" class=\"data row9 col0\" >0.8994</td>\n",
       "      <td id=\"T_8d269_row9_col1\" class=\"data row9 col1\" >0.9590</td>\n",
       "      <td id=\"T_8d269_row9_col2\" class=\"data row9 col2\" >0.8804</td>\n",
       "      <td id=\"T_8d269_row9_col3\" class=\"data row9 col3\" >0.9173</td>\n",
       "      <td id=\"T_8d269_row9_col4\" class=\"data row9 col4\" >0.8985</td>\n",
       "      <td id=\"T_8d269_row9_col5\" class=\"data row9 col5\" >0.7988</td>\n",
       "      <td id=\"T_8d269_row9_col6\" class=\"data row9 col6\" >0.7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_8d269_row10_col0\" class=\"data row10 col0\" >0.9017</td>\n",
       "      <td id=\"T_8d269_row10_col1\" class=\"data row10 col1\" >0.9609</td>\n",
       "      <td id=\"T_8d269_row10_col2\" class=\"data row10 col2\" >0.8843</td>\n",
       "      <td id=\"T_8d269_row10_col3\" class=\"data row10 col3\" >0.9182</td>\n",
       "      <td id=\"T_8d269_row10_col4\" class=\"data row10 col4\" >0.9009</td>\n",
       "      <td id=\"T_8d269_row10_col5\" class=\"data row10 col5\" >0.8035</td>\n",
       "      <td id=\"T_8d269_row10_col6\" class=\"data row10 col6\" >0.8041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d269_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_8d269_row11_col0\" class=\"data row11 col0\" >0.0069</td>\n",
       "      <td id=\"T_8d269_row11_col1\" class=\"data row11 col1\" >0.0038</td>\n",
       "      <td id=\"T_8d269_row11_col2\" class=\"data row11 col2\" >0.0101</td>\n",
       "      <td id=\"T_8d269_row11_col3\" class=\"data row11 col3\" >0.0079</td>\n",
       "      <td id=\"T_8d269_row11_col4\" class=\"data row11 col4\" >0.0071</td>\n",
       "      <td id=\"T_8d269_row11_col5\" class=\"data row11 col5\" >0.0138</td>\n",
       "      <td id=\"T_8d269_row11_col6\" class=\"data row11 col6\" >0.0137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13970ef41c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the best model after evaluating through pycaret\n",
    "lr = create_model('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61de9b14-7f69-403d-b05c-f9c4ca65cb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c0469_row10_col0, #T_c0469_row10_col1, #T_c0469_row10_col2, #T_c0469_row10_col3, #T_c0469_row10_col4, #T_c0469_row10_col5, #T_c0469_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c0469\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c0469_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c0469_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_c0469_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_c0469_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_c0469_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_c0469_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_c0469_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c0469_row0_col0\" class=\"data row0 col0\" >0.9025</td>\n",
       "      <td id=\"T_c0469_row0_col1\" class=\"data row0 col1\" >0.9599</td>\n",
       "      <td id=\"T_c0469_row0_col2\" class=\"data row0 col2\" >0.8865</td>\n",
       "      <td id=\"T_c0469_row0_col3\" class=\"data row0 col3\" >0.9178</td>\n",
       "      <td id=\"T_c0469_row0_col4\" class=\"data row0 col4\" >0.9019</td>\n",
       "      <td id=\"T_c0469_row0_col5\" class=\"data row0 col5\" >0.8051</td>\n",
       "      <td id=\"T_c0469_row0_col6\" class=\"data row0 col6\" >0.8056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c0469_row1_col0\" class=\"data row1 col0\" >0.9006</td>\n",
       "      <td id=\"T_c0469_row1_col1\" class=\"data row1 col1\" >0.9581</td>\n",
       "      <td id=\"T_c0469_row1_col2\" class=\"data row1 col2\" >0.8764</td>\n",
       "      <td id=\"T_c0469_row1_col3\" class=\"data row1 col3\" >0.9230</td>\n",
       "      <td id=\"T_c0469_row1_col4\" class=\"data row1 col4\" >0.8991</td>\n",
       "      <td id=\"T_c0469_row1_col5\" class=\"data row1 col5\" >0.8014</td>\n",
       "      <td id=\"T_c0469_row1_col6\" class=\"data row1 col6\" >0.8024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c0469_row2_col0\" class=\"data row2 col0\" >0.8981</td>\n",
       "      <td id=\"T_c0469_row2_col1\" class=\"data row2 col1\" >0.9586</td>\n",
       "      <td id=\"T_c0469_row2_col2\" class=\"data row2 col2\" >0.8802</td>\n",
       "      <td id=\"T_c0469_row2_col3\" class=\"data row2 col3\" >0.9148</td>\n",
       "      <td id=\"T_c0469_row2_col4\" class=\"data row2 col4\" >0.8972</td>\n",
       "      <td id=\"T_c0469_row2_col5\" class=\"data row2 col5\" >0.7962</td>\n",
       "      <td id=\"T_c0469_row2_col6\" class=\"data row2 col6\" >0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c0469_row3_col0\" class=\"data row3 col0\" >0.9210</td>\n",
       "      <td id=\"T_c0469_row3_col1\" class=\"data row3 col1\" >0.9698</td>\n",
       "      <td id=\"T_c0469_row3_col2\" class=\"data row3 col2\" >0.9067</td>\n",
       "      <td id=\"T_c0469_row3_col3\" class=\"data row3 col3\" >0.9350</td>\n",
       "      <td id=\"T_c0469_row3_col4\" class=\"data row3 col4\" >0.9206</td>\n",
       "      <td id=\"T_c0469_row3_col5\" class=\"data row3 col5\" >0.8421</td>\n",
       "      <td id=\"T_c0469_row3_col6\" class=\"data row3 col6\" >0.8425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c0469_row4_col0\" class=\"data row4 col0\" >0.9019</td>\n",
       "      <td id=\"T_c0469_row4_col1\" class=\"data row4 col1\" >0.9628</td>\n",
       "      <td id=\"T_c0469_row4_col2\" class=\"data row4 col2\" >0.8852</td>\n",
       "      <td id=\"T_c0469_row4_col3\" class=\"data row4 col3\" >0.9176</td>\n",
       "      <td id=\"T_c0469_row4_col4\" class=\"data row4 col4\" >0.9012</td>\n",
       "      <td id=\"T_c0469_row4_col5\" class=\"data row4 col5\" >0.8039</td>\n",
       "      <td id=\"T_c0469_row4_col6\" class=\"data row4 col6\" >0.8044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c0469_row5_col0\" class=\"data row5 col0\" >0.8962</td>\n",
       "      <td id=\"T_c0469_row5_col1\" class=\"data row5 col1\" >0.9584</td>\n",
       "      <td id=\"T_c0469_row5_col2\" class=\"data row5 col2\" >0.8865</td>\n",
       "      <td id=\"T_c0469_row5_col3\" class=\"data row5 col3\" >0.9059</td>\n",
       "      <td id=\"T_c0469_row5_col4\" class=\"data row5 col4\" >0.8961</td>\n",
       "      <td id=\"T_c0469_row5_col5\" class=\"data row5 col5\" >0.7924</td>\n",
       "      <td id=\"T_c0469_row5_col6\" class=\"data row5 col6\" >0.7926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c0469_row6_col0\" class=\"data row6 col0\" >0.9006</td>\n",
       "      <td id=\"T_c0469_row6_col1\" class=\"data row6 col1\" >0.9654</td>\n",
       "      <td id=\"T_c0469_row6_col2\" class=\"data row6 col2\" >0.8840</td>\n",
       "      <td id=\"T_c0469_row6_col3\" class=\"data row6 col3\" >0.9163</td>\n",
       "      <td id=\"T_c0469_row6_col4\" class=\"data row6 col4\" >0.8999</td>\n",
       "      <td id=\"T_c0469_row6_col5\" class=\"data row6 col5\" >0.8013</td>\n",
       "      <td id=\"T_c0469_row6_col6\" class=\"data row6 col6\" >0.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c0469_row7_col0\" class=\"data row7 col0\" >0.8981</td>\n",
       "      <td id=\"T_c0469_row7_col1\" class=\"data row7 col1\" >0.9608</td>\n",
       "      <td id=\"T_c0469_row7_col2\" class=\"data row7 col2\" >0.8827</td>\n",
       "      <td id=\"T_c0469_row7_col3\" class=\"data row7 col3\" >0.9126</td>\n",
       "      <td id=\"T_c0469_row7_col4\" class=\"data row7 col4\" >0.8974</td>\n",
       "      <td id=\"T_c0469_row7_col5\" class=\"data row7 col5\" >0.7962</td>\n",
       "      <td id=\"T_c0469_row7_col6\" class=\"data row7 col6\" >0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c0469_row8_col0\" class=\"data row8 col0\" >0.8975</td>\n",
       "      <td id=\"T_c0469_row8_col1\" class=\"data row8 col1\" >0.9576</td>\n",
       "      <td id=\"T_c0469_row8_col2\" class=\"data row8 col2\" >0.8703</td>\n",
       "      <td id=\"T_c0469_row8_col3\" class=\"data row8 col3\" >0.9226</td>\n",
       "      <td id=\"T_c0469_row8_col4\" class=\"data row8 col4\" >0.8957</td>\n",
       "      <td id=\"T_c0469_row8_col5\" class=\"data row8 col5\" >0.7950</td>\n",
       "      <td id=\"T_c0469_row8_col6\" class=\"data row8 col6\" >0.7963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c0469_row9_col0\" class=\"data row9 col0\" >0.8936</td>\n",
       "      <td id=\"T_c0469_row9_col1\" class=\"data row9 col1\" >0.9584</td>\n",
       "      <td id=\"T_c0469_row9_col2\" class=\"data row9 col2\" >0.8728</td>\n",
       "      <td id=\"T_c0469_row9_col3\" class=\"data row9 col3\" >0.9130</td>\n",
       "      <td id=\"T_c0469_row9_col4\" class=\"data row9 col4\" >0.8925</td>\n",
       "      <td id=\"T_c0469_row9_col5\" class=\"data row9 col5\" >0.7873</td>\n",
       "      <td id=\"T_c0469_row9_col6\" class=\"data row9 col6\" >0.7881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_c0469_row10_col0\" class=\"data row10 col0\" >0.9010</td>\n",
       "      <td id=\"T_c0469_row10_col1\" class=\"data row10 col1\" >0.9610</td>\n",
       "      <td id=\"T_c0469_row10_col2\" class=\"data row10 col2\" >0.8831</td>\n",
       "      <td id=\"T_c0469_row10_col3\" class=\"data row10 col3\" >0.9179</td>\n",
       "      <td id=\"T_c0469_row10_col4\" class=\"data row10 col4\" >0.9001</td>\n",
       "      <td id=\"T_c0469_row10_col5\" class=\"data row10 col5\" >0.8021</td>\n",
       "      <td id=\"T_c0469_row10_col6\" class=\"data row10 col6\" >0.8027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0469_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_c0469_row11_col0\" class=\"data row11 col0\" >0.0072</td>\n",
       "      <td id=\"T_c0469_row11_col1\" class=\"data row11 col1\" >0.0038</td>\n",
       "      <td id=\"T_c0469_row11_col2\" class=\"data row11 col2\" >0.0095</td>\n",
       "      <td id=\"T_c0469_row11_col3\" class=\"data row11 col3\" >0.0074</td>\n",
       "      <td id=\"T_c0469_row11_col4\" class=\"data row11 col4\" >0.0073</td>\n",
       "      <td id=\"T_c0469_row11_col5\" class=\"data row11 col5\" >0.0143</td>\n",
       "      <td id=\"T_c0469_row11_col6\" class=\"data row11 col6\" >0.0142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x138d81d8c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    }
   ],
   "source": [
    "# Optimising the hyperparameters of the LogReg model\n",
    "tuned_log_reg = tune_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c388bd6-61bc-4aec-a2e4-85a5a54ceaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best params from the tuned log_reg\n",
    "tuned_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc2a46-d757-407e-8012-ef020f26ab80",
   "metadata": {},
   "source": [
    "The tuned log_reg has similar parameters from the best_model of LogReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f77f1cb5-e4f1-4963-816e-0865df13eeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look into the confusion matrix of the pycaret-train set versus pycaret-test set (hold-out set)\n",
    "plot_model(tuned_log_reg, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57d0b276-9b6f-4c68-8c0a-ef8355831a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_01b77\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_01b77_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_01b77_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_01b77_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_01b77_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_01b77_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_01b77_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_01b77_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_01b77_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_01b77_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_01b77_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_01b77_row0_col1\" class=\"data row0 col1\" >0.9068</td>\n",
       "      <td id=\"T_01b77_row0_col2\" class=\"data row0 col2\" >0.9620</td>\n",
       "      <td id=\"T_01b77_row0_col3\" class=\"data row0 col3\" >0.8932</td>\n",
       "      <td id=\"T_01b77_row0_col4\" class=\"data row0 col4\" >0.9200</td>\n",
       "      <td id=\"T_01b77_row0_col5\" class=\"data row0 col5\" >0.9064</td>\n",
       "      <td id=\"T_01b77_row0_col6\" class=\"data row0 col6\" >0.8137</td>\n",
       "      <td id=\"T_01b77_row0_col7\" class=\"data row0 col7\" >0.8141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x138ee428400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abort</th>\n",
       "      <th>abov</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absenc</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>is_anxiety</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15700</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6730 rows  3003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abandon   abdomen  abdomin      abil       abl  abnorm  abort  \\\n",
       "15700      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15701      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15702      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15703      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15704      0.0  0.000000      0.0  0.000000  0.091602     0.0    0.0   \n",
       "...        ...       ...      ...       ...       ...     ...    ...   \n",
       "22425      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "22426      0.0  0.000000      0.0  0.000000  0.026062     0.0    0.0   \n",
       "22427      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "22428      0.0  0.140314      0.0  0.108733  0.000000     0.0    0.0   \n",
       "22429      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "\n",
       "           abov  abroad  absenc  ...   yr  zap      zero  zoloft  zombi  zone  \\\n",
       "15700  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15701  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15702  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15703  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15704  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "...         ...     ...     ...  ...  ...  ...       ...     ...    ...   ...   \n",
       "22425  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "22426  0.043377     0.0     0.0  ...  0.0  0.0  0.086924     0.0    0.0   0.0   \n",
       "22427  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "22428  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "22429  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "\n",
       "       zoom  is_anxiety  prediction_label  prediction_score  \n",
       "15700   0.0           1                 1            0.9795  \n",
       "15701   0.0           1                 1            0.9991  \n",
       "15702   0.0           0                 0            0.8592  \n",
       "15703   0.0           1                 1            0.9889  \n",
       "15704   0.0           0                 1            0.7098  \n",
       "...     ...         ...               ...               ...  \n",
       "22425   0.0           0                 0            0.9912  \n",
       "22426   0.0           1                 0            0.6080  \n",
       "22427   0.0           1                 1            0.8330  \n",
       "22428   0.0           1                 1            0.9978  \n",
       "22429   0.0           1                 1            0.9136  \n",
       "\n",
       "[6730 rows x 3003 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pycaret-test set (hold out set) on the Pycaret trained model for LogReg\n",
    "predict_model(tuned_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "099f3a57-aaa9-423b-9647-0821b93bad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the entire pycaret_df which includes the hold_out set\n",
    "final_lr = finalize_model(tuned_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc43e86d-1a6a-494c-9ffb-632bd0ead208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=Memory(location=C:\\Users\\CALERL~1\\AppData\\Local\\Temp\\joblib),\n",
       "         steps=[(&#x27;numerical_imputer&#x27;,\n",
       "                 TransformerWrapper(exclude=None,\n",
       "                                    include=[&#x27;abandon&#x27;, &#x27;abdomen&#x27;, &#x27;abdomin&#x27;,\n",
       "                                             &#x27;abil&#x27;, &#x27;abl&#x27;, &#x27;abnorm&#x27;, &#x27;abort&#x27;,\n",
       "                                             &#x27;abov&#x27;, &#x27;abroad&#x27;, &#x27;absenc&#x27;,\n",
       "                                             &#x27;absent&#x27;, &#x27;absolut&#x27;, &#x27;absorb&#x27;,\n",
       "                                             &#x27;abt&#x27;, &#x27;abus&#x27;, &#x27;academ&#x27;, &#x27;accept&#x27;,\n",
       "                                             &#x27;access&#x27;, &#x27;accid&#x27;, &#x27;accident&#x27;,\n",
       "                                             &#x27;accommod&#x27;, &#x27;accompani&#x27;,\n",
       "                                             &#x27;accompli...\n",
       "                 TransformerWrapper(exclude=[], include=None,\n",
       "                                    transformer=VarianceThreshold(threshold=0))),\n",
       "                (&#x27;actual_estimator&#x27;,\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class=&#x27;auto&#x27;, n_jobs=None,\n",
       "                                    penalty=&#x27;l2&#x27;, random_state=42,\n",
       "                                    solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=Memory(location=C:\\Users\\CALERL~1\\AppData\\Local\\Temp\\joblib),\n",
       "         steps=[(&#x27;numerical_imputer&#x27;,\n",
       "                 TransformerWrapper(exclude=None,\n",
       "                                    include=[&#x27;abandon&#x27;, &#x27;abdomen&#x27;, &#x27;abdomin&#x27;,\n",
       "                                             &#x27;abil&#x27;, &#x27;abl&#x27;, &#x27;abnorm&#x27;, &#x27;abort&#x27;,\n",
       "                                             &#x27;abov&#x27;, &#x27;abroad&#x27;, &#x27;absenc&#x27;,\n",
       "                                             &#x27;absent&#x27;, &#x27;absolut&#x27;, &#x27;absorb&#x27;,\n",
       "                                             &#x27;abt&#x27;, &#x27;abus&#x27;, &#x27;academ&#x27;, &#x27;accept&#x27;,\n",
       "                                             &#x27;access&#x27;, &#x27;accid&#x27;, &#x27;accident&#x27;,\n",
       "                                             &#x27;accommod&#x27;, &#x27;accompani&#x27;,\n",
       "                                             &#x27;accompli...\n",
       "                 TransformerWrapper(exclude=[], include=None,\n",
       "                                    transformer=VarianceThreshold(threshold=0))),\n",
       "                (&#x27;actual_estimator&#x27;,\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class=&#x27;auto&#x27;, n_jobs=None,\n",
       "                                    penalty=&#x27;l2&#x27;, random_state=42,\n",
       "                                    solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None,\n",
       "                   include=[&#x27;abandon&#x27;, &#x27;abdomen&#x27;, &#x27;abdomin&#x27;, &#x27;abil&#x27;, &#x27;abl&#x27;,\n",
       "                            &#x27;abnorm&#x27;, &#x27;abort&#x27;, &#x27;abov&#x27;, &#x27;abroad&#x27;, &#x27;absenc&#x27;,\n",
       "                            &#x27;absent&#x27;, &#x27;absolut&#x27;, &#x27;absorb&#x27;, &#x27;abt&#x27;, &#x27;abus&#x27;,\n",
       "                            &#x27;academ&#x27;, &#x27;accept&#x27;, &#x27;access&#x27;, &#x27;accid&#x27;, &#x27;accident&#x27;,\n",
       "                            &#x27;accommod&#x27;, &#x27;accompani&#x27;, &#x27;accomplish&#x27;, &#x27;accord&#x27;,\n",
       "                            &#x27;account&#x27;, &#x27;accus&#x27;, &#x27;ach&#x27;, &#x27;achiev&#x27;, &#x27;acid&#x27;,\n",
       "                            &#x27;acknowledg&#x27;, ...],\n",
       "                   transformer=SimpleImputer(add_indicator=False, copy=True,\n",
       "                                             fill_value=None,\n",
       "                                             missing_values=nan,\n",
       "                                             strategy=&#x27;mean&#x27;,\n",
       "                                             verbose=&#x27;deprecated&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=None, include=[],\n",
       "                   transformer=SimpleImputer(add_indicator=False, copy=True,\n",
       "                                             fill_value=&#x27;constant&#x27;,\n",
       "                                             missing_values=nan,\n",
       "                                             strategy=&#x27;constant&#x27;,\n",
       "                                             verbose=&#x27;deprecated&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;constant&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;constant&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">low_variance: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(exclude=[], include=None,\n",
       "                   transformer=VarianceThreshold(threshold=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory=Memory(location=C:\\Users\\CALERL~1\\AppData\\Local\\Temp\\joblib),\n",
       "         steps=[('numerical_imputer',\n",
       "                 TransformerWrapper(exclude=None,\n",
       "                                    include=['abandon', 'abdomen', 'abdomin',\n",
       "                                             'abil', 'abl', 'abnorm', 'abort',\n",
       "                                             'abov', 'abroad', 'absenc',\n",
       "                                             'absent', 'absolut', 'absorb',\n",
       "                                             'abt', 'abus', 'academ', 'accept',\n",
       "                                             'access', 'accid', 'accident',\n",
       "                                             'accommod', 'accompani',\n",
       "                                             'accompli...\n",
       "                 TransformerWrapper(exclude=[], include=None,\n",
       "                                    transformer=VarianceThreshold(threshold=0))),\n",
       "                ('actual_estimator',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=1000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=42,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3bf4e510-5b33-4e40-af5e-3f4d88c430a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_aa084\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa084_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_aa084_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_aa084_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_aa084_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_aa084_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_aa084_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_aa084_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_aa084_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa084_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa084_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_aa084_row0_col1\" class=\"data row0 col1\" >0.9264</td>\n",
       "      <td id=\"T_aa084_row0_col2\" class=\"data row0 col2\" >0.9727</td>\n",
       "      <td id=\"T_aa084_row0_col3\" class=\"data row0 col3\" >0.9121</td>\n",
       "      <td id=\"T_aa084_row0_col4\" class=\"data row0 col4\" >0.9406</td>\n",
       "      <td id=\"T_aa084_row0_col5\" class=\"data row0 col5\" >0.9261</td>\n",
       "      <td id=\"T_aa084_row0_col6\" class=\"data row0 col6\" >0.8529</td>\n",
       "      <td id=\"T_aa084_row0_col7\" class=\"data row0 col7\" >0.8533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x138e06a8f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abort</th>\n",
       "      <th>abov</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absenc</th>\n",
       "      <th>...</th>\n",
       "      <th>yr</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>is_anxiety</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15700</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6730 rows  3003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abandon   abdomen  abdomin      abil       abl  abnorm  abort  \\\n",
       "15700      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15701      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15702      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15703      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "15704      0.0  0.000000      0.0  0.000000  0.091602     0.0    0.0   \n",
       "...        ...       ...      ...       ...       ...     ...    ...   \n",
       "22425      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "22426      0.0  0.000000      0.0  0.000000  0.026062     0.0    0.0   \n",
       "22427      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "22428      0.0  0.140314      0.0  0.108733  0.000000     0.0    0.0   \n",
       "22429      0.0  0.000000      0.0  0.000000  0.000000     0.0    0.0   \n",
       "\n",
       "           abov  abroad  absenc  ...   yr  zap      zero  zoloft  zombi  zone  \\\n",
       "15700  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15701  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15702  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15703  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "15704  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "...         ...     ...     ...  ...  ...  ...       ...     ...    ...   ...   \n",
       "22425  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "22426  0.043377     0.0     0.0  ...  0.0  0.0  0.086924     0.0    0.0   0.0   \n",
       "22427  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "22428  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "22429  0.000000     0.0     0.0  ...  0.0  0.0  0.000000     0.0    0.0   0.0   \n",
       "\n",
       "       zoom  is_anxiety  prediction_label  prediction_score  \n",
       "15700   0.0           1                 1            0.9835  \n",
       "15701   0.0           1                 1            0.9995  \n",
       "15702   0.0           0                 0            0.8210  \n",
       "15703   0.0           1                 1            0.9931  \n",
       "15704   0.0           0                 1            0.7529  \n",
       "...     ...         ...               ...               ...  \n",
       "22425   0.0           0                 0            0.9937  \n",
       "22426   0.0           1                 0            0.5293  \n",
       "22427   0.0           1                 1            0.8611  \n",
       "22428   0.0           1                 1            0.9989  \n",
       "22429   0.0           1                 1            0.9246  \n",
       "\n",
       "[6730 rows x 3003 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the prediction from the finalised model of LogReg\n",
    "predict_model(final_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea029951-3412-482d-bf4a-3e1100dfc002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the vectorized X_test in a dataframe with the y_test values\n",
    "test_df = pd.concat([X_test_tfidf_df, y_test.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7af8909d-5368-4e7e-98bf-4f7965be3309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7477, 3001)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d622a73-decf-44cc-b3ff-fea34cca2d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomin</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abort</th>\n",
       "      <th>abov</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absenc</th>\n",
       "      <th>...</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>is_anxiety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abdomen  abdomin  abil  abl  abnorm  abort  abov  abroad  absenc  \\\n",
       "0      0.0      0.0      0.0   0.0  0.0     0.0    0.0   0.0     0.0     0.0   \n",
       "1      0.0      0.0      0.0   0.0  0.0     0.0    0.0   0.0     0.0     0.0   \n",
       "2      0.0      0.0      0.0   0.0  0.0     0.0    0.0   0.0     0.0     0.0   \n",
       "3      0.0      0.0      0.0   0.0  0.0     0.0    0.0   0.0     0.0     0.0   \n",
       "4      0.0      0.0      0.0   0.0  0.0     0.0    0.0   0.0     0.0     0.0   \n",
       "\n",
       "   ...  youtu  youtub   yr  zap  zero  zoloft  zombi  zone  zoom  is_anxiety  \n",
       "0  ...    0.0     0.0  0.0  0.0   0.0     0.0    0.0   0.0   0.0           0  \n",
       "1  ...    0.0     0.0  0.0  0.0   0.0     0.0    0.0   0.0   0.0           1  \n",
       "2  ...    0.0     0.0  0.0  0.0   0.0     0.0    0.0   0.0   0.0           0  \n",
       "3  ...    0.0     0.0  0.0  0.0   0.0     0.0    0.0   0.0   0.0           1  \n",
       "4  ...    0.0     0.0  0.0  0.0   0.0     0.0    0.0   0.0   0.0           0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that is correctly concatenated\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e45aa62-2513-409d-86da-ac60b9a456e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e8d6c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e8d6c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e8d6c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e8d6c_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e8d6c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_e8d6c_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_e8d6c_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_e8d6c_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_e8d6c_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e8d6c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e8d6c_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_e8d6c_row0_col1\" class=\"data row0 col1\" >0.9060</td>\n",
       "      <td id=\"T_e8d6c_row0_col2\" class=\"data row0 col2\" >0.9613</td>\n",
       "      <td id=\"T_e8d6c_row0_col3\" class=\"data row0 col3\" >0.8878</td>\n",
       "      <td id=\"T_e8d6c_row0_col4\" class=\"data row0 col4\" >0.9232</td>\n",
       "      <td id=\"T_e8d6c_row0_col5\" class=\"data row0 col5\" >0.9051</td>\n",
       "      <td id=\"T_e8d6c_row0_col6\" class=\"data row0 col6\" >0.8120</td>\n",
       "      <td id=\"T_e8d6c_row0_col7\" class=\"data row0 col7\" >0.8126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x138e83098b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing the finalized model of LogReg with the test data set\n",
    "lr_pred = predict_model(final_lr, data=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2272a8d8-013c-49f9-a342-70d7071d1f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_anxiety</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7477 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_anxiety  prediction_label  prediction_score\n",
       "0              0                 0            0.7526\n",
       "1              1                 1            0.9993\n",
       "2              0                 0            0.8161\n",
       "3              1                 1            0.9547\n",
       "4              0                 0            0.7968\n",
       "...          ...               ...               ...\n",
       "7472           1                 1            0.9652\n",
       "7473           1                 0            0.5892\n",
       "7474           1                 1            0.9546\n",
       "7475           0                 0            0.9086\n",
       "7476           1                 1            0.6895\n",
       "\n",
       "[7477 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A look into the test data, prediction_label and prediction_score\n",
    "lr_pred[['is_anxiety','prediction_label','prediction_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80f960-559a-4d90-b589-bc4e0c45dde4",
   "metadata": {},
   "source": [
    "- Through the evaluation of the data through Pycaret models after vectorizing, for the finalised model of LogReg has the highest accuracy score of train (0.926)/92.6% and test(0.906)/90.6%. \n",
    "- Pycaret (0.906) has higher test score than the base model(0.886) and similar scores to pipeline 2(0.906)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f9ad5-6f88-4821-b541-a95ffd87e77e",
   "metadata": {},
   "source": [
    "# Evaluation of Pipeline 3 and Pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc1e78b-7e7e-472a-a3a5-767e4ffef21b",
   "metadata": {},
   "source": [
    "|Pipeline|Vectorizer|Estimator|Parameters for Vectorizer|Parameters for Estimator|Train|Test\n",
    "|----|----|----|----|----|----|----|\n",
    "|Base|CountVectorizer|Logsitic Regression|-|max_iter = 700|0.971|0.886|\n",
    "|3|TFIDF|RandomForest|max_df = 0.9, max_features = 3000, min_df = 2, ngram_range: (1,1), stop_words = custom_stop_words, Tokenizer = StemmTokenizer|max_depth= 4, n_estimators= 200|0.871|0.863|\n",
    "|Pycaret|TFIDF|Logistic Regression|max_df = 0.9, max_features = 3000, min_df = 2, ngram_range: (1,1), stop_words = custom_stop_words, Tokenizer = StemmTokenizer|c=1, max_iter = 1000|0.926|0.906|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d26ba-4a4c-460b-a06d-d71256569c69",
   "metadata": {},
   "source": [
    "In the next code notebook (Notebook 5), HuggingFace models are explored."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
