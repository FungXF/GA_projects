{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e06289-0f35-4e84-9daa-4bae964aa2b1",
   "metadata": {},
   "source": [
    "# Reddit Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d337b2d-072e-4c2e-82f3-d760d6e3bb7b",
   "metadata": {},
   "source": [
    "## Notebook 1 of 5 - Scraping Data\n",
    "- There are a total of 5 notebooks\n",
    "- Due to the processing power required, the modelling is seperated into 3 code notebooks (Notebook 3,4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec3798-6034-45ff-8802-436e96e891d7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Mental health is critically important to everyone, everywhere. All over the world, mental health needs are high but responses are insufficient and inadequate. This issue is prevalent in all countries including first world countries. However, one of the pervasive issues the report covers is stigma. Stigma wears many faces. We most commonly equate it with how we treat one other. However, that represents only part of the issue; personal shame, internalized through an individualâ€™s mental health suffering, is a silent problem. We must normalize talking about mental health and its multitude of conditions because stigma is the chain onto which all mental health conditions link. [WHO Article](https://www.who.int/news-room/commentaries/detail/world-mental-health-day-is-an-opportunity-for-us-to-embrace-our-sense-of-community-and-normalize-mental-health)\n",
    "- Thus, there are cases where people do not know if they need help or they do know but do not know where to look for help.\n",
    "- Due to stigmatism, there is a possibility that people try to self-medicate or they go on to social media platforms to write their feelings but did not seek help.\n",
    "- Thus, this project would bring about the first step in correctly classifying the topics based on NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ef3ab-f6d8-4656-ac83-423035b168c9",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "1. Through natural language processing and classification models, How can we classify posts based on the texts used by people who may be depressed or anxious? \n",
    "\n",
    "2. How can sentiment analysis be utilized to detect primary and secondary emotions from the posts?\n",
    "\n",
    "- To correctly classify on anxiety and depression based the subreddit posts in these two topics.\n",
    "- The vectorizers that will be deployed are CountVectorizer and TfidfVectorizer\n",
    "- The models used are Logistic Regression, KNearestNeighbors, MultinomialNB, RandomForest and Pycaret.\n",
    "- The main metrics used for evaluating the performance of the models is accuracy.\n",
    "- Hugging Face models will also be explored in these notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715259d-d4f1-4ea9-880b-c073d06cf2b5",
   "metadata": {},
   "source": [
    "## Target Audience\n",
    "As a Data Science enthusiast and a fellow reddit user who is promoting the usage of NLP for moderators to detect emotions based on redditors's posts by joining as a speaker of World Health Day Convention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca938252-e3fe-471a-a1d4-913ee2f44743",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "- There are two datasets from two reddit topics, 'Anxiety' and 'depression' which were scrapped using Pushshift API.\n",
    "- Each dataset has more than 15000 post from each topic\n",
    "- The duration of the scrap will start with the latest post from 03 Oct 2022 to earlier post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04642a9-e997-45a0-a9b2-5e8a0a0fbc73",
   "metadata": {},
   "source": [
    "# Scrapping Reddit posts using Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a63d66-9972-4853-9d3f-2c2f83c69306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b71121-5b83-4f45-acba-b49577d8c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grab posts from the subreddit.\n",
    " \n",
    "def getposts(subreddit): \n",
    " \n",
    "    timing = 1664755200 # the timing is set at GMT+0 Monday 12.00am 03 Oct 2022\n",
    "    posts_number = 0 # set posts_number to zero. the loop will make use of this.\n",
    "    total_post = [] # create an empty list for the post\n",
    "\n",
    "    while True:\n",
    "        url = 'https://api.pushshift.io/reddit/search/submission' # pushshift API site\n",
    "        params = {\n",
    "            'subreddit': subreddit, # the subreddit \n",
    "            'size': 250, # max limit for Pushshift API\n",
    "            'before': timing # the first time will be the one defined above.\n",
    "        }\n",
    "        print(f'Scraping through subreddit: {subreddit}. Total post so far: {posts_number}') # show count\n",
    "        res = requests.get(url, params) # requesting url with the params\n",
    "        data = res.json() # save from the website into json and then store it as data.\n",
    "        posts = data['data'] # inside column 'data' in data is where the information we want.\n",
    "                \n",
    "        for i in range(len(posts)):\n",
    "            post = {}\n",
    "            epoch_time = posts[i]['created_utc'] # find the [i] post epoch time\n",
    "            date_time = datetime.datetime.fromtimestamp(epoch_time) # convert the epoch time to standard time (UTC)\n",
    "                 \n",
    "            try:\n",
    "                post['date_time'] = date_time.strftime('%Y-%m-%d %H:%M:%S') # save the time as a datetime format\n",
    "            except:\n",
    "                post['date_time'] = 'post deleted' # if posts gets deleted and throws an error, input text as post deleted           \n",
    "            try:\n",
    "                post['subreddit'] = posts[i]['subreddit'] # save the subreddit name\n",
    "            except:\n",
    "                post['subreddit'] = 'post deleted' #incase posts gets deleted and throws an error, input text as post deleted\n",
    "            try:\n",
    "                post['selftext'] = posts[i]['selftext'] # save the selftext data\n",
    "            except:\n",
    "                post['selftext'] = 'post deleted' # if posts gets deleted and throws an error, input text as post deleted\n",
    "            try: \n",
    "                post['title'] = posts[i]['title'] # save the post title\n",
    "            except:\n",
    "                post['title'] = 'post deleted' # if posts gets deleted and throws an error, input text as post deleted\n",
    "                       \n",
    "            total_post.append(post) # append this current post dictionary, and put it ito total_post list.\n",
    "        \n",
    "        posts_number += len(posts) # add to post_number for counter and for the while true loop.\n",
    "        max_post = len(post)\n",
    "        timing = posts[-1]['created_utc'] # set the new timing from the last post in posts list \n",
    "        \n",
    "\n",
    "        if posts_number >= 15000: # if this is true, the while loop breaks\n",
    "            print(f\" Completed. Total post : {posts_number}\") # once its done, it will print completed\n",
    "            break\n",
    "    \n",
    "    posts_df = pd.DataFrame(total_post) # saves the total_post from the subreddit and place it in a posts_df(dataframe)\n",
    "    posts_df.to_csv('./datasets/'+subreddit+'.csv') # saves the file name into dataset folder, with the subreddit name.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5d79ef8-7997-46b3-8035-170b94e95ae6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping through subreddit: Anxiety. Total post so far: 0\n",
      "Scraping through subreddit: Anxiety. Total post so far: 250\n",
      "Scraping through subreddit: Anxiety. Total post so far: 500\n",
      "Scraping through subreddit: Anxiety. Total post so far: 750\n",
      "Scraping through subreddit: Anxiety. Total post so far: 1000\n",
      "Scraping through subreddit: Anxiety. Total post so far: 1250\n",
      "Scraping through subreddit: Anxiety. Total post so far: 1500\n",
      "Scraping through subreddit: Anxiety. Total post so far: 1750\n",
      "Scraping through subreddit: Anxiety. Total post so far: 1999\n",
      "Scraping through subreddit: Anxiety. Total post so far: 2249\n",
      "Scraping through subreddit: Anxiety. Total post so far: 2499\n",
      "Scraping through subreddit: Anxiety. Total post so far: 2749\n",
      "Scraping through subreddit: Anxiety. Total post so far: 2999\n",
      "Scraping through subreddit: Anxiety. Total post so far: 3249\n",
      "Scraping through subreddit: Anxiety. Total post so far: 3499\n",
      "Scraping through subreddit: Anxiety. Total post so far: 3748\n",
      "Scraping through subreddit: Anxiety. Total post so far: 3998\n",
      "Scraping through subreddit: Anxiety. Total post so far: 4248\n",
      "Scraping through subreddit: Anxiety. Total post so far: 4498\n",
      "Scraping through subreddit: Anxiety. Total post so far: 4748\n",
      "Scraping through subreddit: Anxiety. Total post so far: 4998\n",
      "Scraping through subreddit: Anxiety. Total post so far: 5248\n",
      "Scraping through subreddit: Anxiety. Total post so far: 5498\n",
      "Scraping through subreddit: Anxiety. Total post so far: 5748\n",
      "Scraping through subreddit: Anxiety. Total post so far: 5998\n",
      "Scraping through subreddit: Anxiety. Total post so far: 6248\n",
      "Scraping through subreddit: Anxiety. Total post so far: 6498\n",
      "Scraping through subreddit: Anxiety. Total post so far: 6748\n",
      "Scraping through subreddit: Anxiety. Total post so far: 6998\n",
      "Scraping through subreddit: Anxiety. Total post so far: 7248\n",
      "Scraping through subreddit: Anxiety. Total post so far: 7498\n",
      "Scraping through subreddit: Anxiety. Total post so far: 7748\n",
      "Scraping through subreddit: Anxiety. Total post so far: 7997\n",
      "Scraping through subreddit: Anxiety. Total post so far: 8247\n",
      "Scraping through subreddit: Anxiety. Total post so far: 8497\n",
      "Scraping through subreddit: Anxiety. Total post so far: 8746\n",
      "Scraping through subreddit: Anxiety. Total post so far: 8996\n",
      "Scraping through subreddit: Anxiety. Total post so far: 9246\n",
      "Scraping through subreddit: Anxiety. Total post so far: 9496\n",
      "Scraping through subreddit: Anxiety. Total post so far: 9746\n",
      "Scraping through subreddit: Anxiety. Total post so far: 9996\n",
      "Scraping through subreddit: Anxiety. Total post so far: 10245\n",
      "Scraping through subreddit: Anxiety. Total post so far: 10495\n",
      "Scraping through subreddit: Anxiety. Total post so far: 10744\n",
      "Scraping through subreddit: Anxiety. Total post so far: 10994\n",
      "Scraping through subreddit: Anxiety. Total post so far: 11244\n",
      "Scraping through subreddit: Anxiety. Total post so far: 11494\n",
      "Scraping through subreddit: Anxiety. Total post so far: 11744\n",
      "Scraping through subreddit: Anxiety. Total post so far: 11994\n",
      "Scraping through subreddit: Anxiety. Total post so far: 12244\n",
      "Scraping through subreddit: Anxiety. Total post so far: 12494\n",
      "Scraping through subreddit: Anxiety. Total post so far: 12744\n",
      "Scraping through subreddit: Anxiety. Total post so far: 12994\n",
      "Scraping through subreddit: Anxiety. Total post so far: 13244\n",
      "Scraping through subreddit: Anxiety. Total post so far: 13494\n",
      "Scraping through subreddit: Anxiety. Total post so far: 13744\n",
      "Scraping through subreddit: Anxiety. Total post so far: 13994\n",
      "Scraping through subreddit: Anxiety. Total post so far: 14244\n",
      "Scraping through subreddit: Anxiety. Total post so far: 14493\n",
      "Scraping through subreddit: Anxiety. Total post so far: 14743\n",
      "Scraping through subreddit: Anxiety. Total post so far: 14992\n",
      " Completed. Total post : 15242\n"
     ]
    }
   ],
   "source": [
    "# Topic 1: Anxiety\n",
    "getposts('Anxiety')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9661506-c9e3-496f-8090-ce30c54f0b5e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping through subreddit: depression. Total post so far: 0\n",
      "Scraping through subreddit: depression. Total post so far: 250\n",
      "Scraping through subreddit: depression. Total post so far: 500\n",
      "Scraping through subreddit: depression. Total post so far: 750\n",
      "Scraping through subreddit: depression. Total post so far: 1000\n",
      "Scraping through subreddit: depression. Total post so far: 1250\n",
      "Scraping through subreddit: depression. Total post so far: 1499\n",
      "Scraping through subreddit: depression. Total post so far: 1749\n",
      "Scraping through subreddit: depression. Total post so far: 1999\n",
      "Scraping through subreddit: depression. Total post so far: 2248\n",
      "Scraping through subreddit: depression. Total post so far: 2497\n",
      "Scraping through subreddit: depression. Total post so far: 2745\n",
      "Scraping through subreddit: depression. Total post so far: 2995\n",
      "Scraping through subreddit: depression. Total post so far: 3245\n",
      "Scraping through subreddit: depression. Total post so far: 3495\n",
      "Scraping through subreddit: depression. Total post so far: 3745\n",
      "Scraping through subreddit: depression. Total post so far: 3995\n",
      "Scraping through subreddit: depression. Total post so far: 4245\n",
      "Scraping through subreddit: depression. Total post so far: 4495\n",
      "Scraping through subreddit: depression. Total post so far: 4745\n",
      "Scraping through subreddit: depression. Total post so far: 4995\n",
      "Scraping through subreddit: depression. Total post so far: 5245\n",
      "Scraping through subreddit: depression. Total post so far: 5495\n",
      "Scraping through subreddit: depression. Total post so far: 5745\n",
      "Scraping through subreddit: depression. Total post so far: 5995\n",
      "Scraping through subreddit: depression. Total post so far: 6244\n",
      "Scraping through subreddit: depression. Total post so far: 6494\n",
      "Scraping through subreddit: depression. Total post so far: 6744\n",
      "Scraping through subreddit: depression. Total post so far: 6994\n",
      "Scraping through subreddit: depression. Total post so far: 7244\n",
      "Scraping through subreddit: depression. Total post so far: 7493\n",
      "Scraping through subreddit: depression. Total post so far: 7742\n",
      "Scraping through subreddit: depression. Total post so far: 7992\n",
      "Scraping through subreddit: depression. Total post so far: 8242\n",
      "Scraping through subreddit: depression. Total post so far: 8492\n",
      "Scraping through subreddit: depression. Total post so far: 8742\n",
      "Scraping through subreddit: depression. Total post so far: 8992\n",
      "Scraping through subreddit: depression. Total post so far: 9241\n",
      "Scraping through subreddit: depression. Total post so far: 9491\n",
      "Scraping through subreddit: depression. Total post so far: 9740\n",
      "Scraping through subreddit: depression. Total post so far: 9990\n",
      "Scraping through subreddit: depression. Total post so far: 10240\n",
      "Scraping through subreddit: depression. Total post so far: 10490\n",
      "Scraping through subreddit: depression. Total post so far: 10738\n",
      "Scraping through subreddit: depression. Total post so far: 10988\n",
      "Scraping through subreddit: depression. Total post so far: 11238\n",
      "Scraping through subreddit: depression. Total post so far: 11488\n",
      "Scraping through subreddit: depression. Total post so far: 11738\n",
      "Scraping through subreddit: depression. Total post so far: 11988\n",
      "Scraping through subreddit: depression. Total post so far: 12238\n",
      "Scraping through subreddit: depression. Total post so far: 12488\n",
      "Scraping through subreddit: depression. Total post so far: 12738\n",
      "Scraping through subreddit: depression. Total post so far: 12988\n",
      "Scraping through subreddit: depression. Total post so far: 13238\n",
      "Scraping through subreddit: depression. Total post so far: 13488\n",
      "Scraping through subreddit: depression. Total post so far: 13738\n",
      "Scraping through subreddit: depression. Total post so far: 13988\n",
      "Scraping through subreddit: depression. Total post so far: 14238\n",
      "Scraping through subreddit: depression. Total post so far: 14488\n",
      "Scraping through subreddit: depression. Total post so far: 14738\n",
      "Scraping through subreddit: depression. Total post so far: 14988\n",
      " Completed. Total post : 15238\n"
     ]
    }
   ],
   "source": [
    "# Topic 2: depression\n",
    "getposts('depression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313dca6-e998-40c8-bc97-05437961fa38",
   "metadata": {},
   "source": [
    "# Data Scraping Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c04de-b876-4e74-b2c1-ff8bbd0f7556",
   "metadata": {},
   "source": [
    "Total 15,242 posts of 'Anxiety' and 15,238 posts of 'depression' were scrapped from subreddit.  \n",
    "This is a total of 30,480 posts.  \n",
    "The next notebook (Notebook 2) will be on Base Model, Data Cleaning and EDA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
